{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":147704369,"sourceType":"kernelVersion"}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"52777f1d-a960-4b1a-9a67-54f6ebaba326","cell_type":"markdown","source":"# Centralised Learning and Federated Learning on the CICIoT2023 dataset\n\nThis notebook extends on the functionality of the CICIoT2023 example notebook, to account for improvement to the centralised training of all data instances.","metadata":{}},{"id":"ef491788-2e80-4cfc-a86b-556eb4624ad8","cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport pickle\nfrom tqdm import tqdm\nimport warnings\n#warnings.filterwarnings('ignore')\n","metadata":{"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T05:19:54.103252Z","iopub.execute_input":"2025-09-22T05:19:54.103963Z","iopub.status.idle":"2025-09-22T05:19:54.107580Z","shell.execute_reply.started":"2025-09-22T05:19:54.103938Z","shell.execute_reply":"2025-09-22T05:19:54.106855Z"}},"outputs":[],"execution_count":88},{"id":"94bf33f7-12e7-4f6e-958b-6b5b0f8b2fbc","cell_type":"code","source":"DATASET_DIRECTORY = '/kaggle/input/creating-a-smaller-dataset-for-ciciot2023/'","metadata":{"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T05:19:54.108840Z","iopub.execute_input":"2025-09-22T05:19:54.109092Z","iopub.status.idle":"2025-09-22T05:19:54.123163Z","shell.execute_reply.started":"2025-09-22T05:19:54.109076Z","shell.execute_reply":"2025-09-22T05:19:54.122449Z"}},"outputs":[],"execution_count":89},{"id":"7618e631","cell_type":"markdown","source":"Include the defines for the dataframe columns and the attack labels and their mappings","metadata":{}},{"id":"6b893d59","cell_type":"code","source":"# from includes import X_columns, y_column, dict_34_classes, dict_8_classes, dict_7_classes, dict_2_classes\n\n\"\"\"\nThis module defines the global variables and dictionaries used in the project.\n\nIt contains definitions for columns used in the dataset, mapping functions for \nthe attack labels, and several dictionaries of attack types for varying classes \nof traffic.\n\nThe dictionaries of attack types include:\n- 34 classes, which includes 33 attack classes and one for benign traffic\n- 8 classes, which includes separate classes for DDoS and DoS attacks\n- 7 classes, which groups DDoS and DoS attacks into a single class\n- 2 classes, which classifies traffic as either benign or malicious\n\"\"\"\n\nfrom enum import Enum\n\n# Define the colours used for text printing\nclass Colours(Enum):\n    RED = \"\\033[31m\"\n    GREEN = \"\\033[32m\"\n    YELLOW = \"\\033[33m\"\n    BLUE = \"\\033[34m\"\n    MAGENTA = \"\\033[35m\"\n    CYAN = \"\\033[36m\"\n    WHITE = \"\\033[37m\"\n    BOLD = \"\\033[1m\"\n    NORMAL = \"\\033[0m\"\n\nX_columns = [\n    'flow_duration', 'header_length', 'protocol_type', 'duration',\n    'rate', 'srate', 'drate', 'fin_flag_number', 'syn_flag_number',\n    'rst_flag_number', 'psh_flag_number', 'ack_flag_number',\n    'ece_flag_number', 'cwr_flag_number', 'ack_count',\n    'syn_count', 'fin_count', 'urg_count', 'rst_count', \n    'http', 'https', 'dns', 'telnet', 'smtp', 'ssh', 'irc', 'tcp',\n    'udp', 'dhcp', 'arp', 'icmp', 'ipv', 'llc', 'tot_sum', 'min',\n    'max', 'avg', 'std', 'tot_size', 'iat', 'number', 'magnitude',\n    'radius', 'covariance', 'variance', 'weight'\n]\n\ny_column = 'label'\n\ndict_34_classes = {'BenignTraffic': 0,\n                    'DDoS-RSTFINFlood' :1, 'DDoS-PSHACK_Flood':2,  'DDoS-SYN_Flood':3, 'DDoS-UDP_Flood':4, 'DDoS-TCP_Flood':5, \n                    'DDoS-ICMP_Flood':6, 'DDoS-SynonymousIP_Flood':7, 'DDoS-ACK_Fragmentation':8, 'DDoS-UDP_Fragmentation':9, 'DDoS-ICMP_Fragmentation':10, \n                    'DDoS-SlowLoris':11, 'DDoS-HTTP_Flood':12, 'DoS-UDP_Flood':13, 'DoS-SYN_Flood':14, 'DoS-TCP_Flood':15, 'DoS-HTTP_Flood':16,\n                    'Mirai-greeth_flood': 17, 'Mirai-greip_flood': 18, 'Mirai-udpplain': 19,\n                    'Recon-PingSweep': 20, 'Recon-OSScan': 21, 'Recon-PortScan': 22, 'VulnerabilityScan': 23, 'Recon-HostDiscovery': 24,\n                    'DNS_Spoofing': 25, 'MITM-ArpSpoofing': 26,\n                    'BrowserHijacking': 27, 'Backdoor_Malware': 28, 'XSS': 29, 'Uploading_Attack': 30, 'SqlInjection': 31, 'CommandInjection': 32,\n                    'DictionaryBruteForce': 33}\n\n# Some parts of the paper talk about 8 classes and split DDoS and DoS into seperate classes\ndict_8_classes = {  0: 0 ,                                                                                                                                      # Benign\n                    1:1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1, 11: 1, 12: 1,                                                                   # DDoS\n                    13: 7, 14: 7, 15: 7, 16: 7,                                                                                                                 # DoS                    \n                    17: 2, 18: 2, 19: 2,                                                                                                                        # Mirai\n                    20: 3, 21: 3, 22: 3, 23: 3, 24: 3,                                                                                                          # Reconnaissance\n                    25: 4, 26: 4,                                                                                                                               # Spoofing\n                    27: 5, 28: 5, 29: 5, 30: 5, 31: 5, 32: 5,                                                                                                   # Web\n                    33: 6}                                                                                                                                      # Brute Force\n\n# Example Notebook provides a \"dict_7classes\" list that is infact 8 classes. This shouldnt be used as far as I can tell                  \ndict_7_classes = {  0: 0 ,                                                                                                                                      # Benign\n                    1 :1, 2:1,  3:1, 4:1, 5:1, 6:1, 7:1, 8:1, 9:1, 10:1, 11:1, 12:1, 13:1, 14:1, 15:1, 16:1,                                                    # DDoS and DoS                    \n                    17: 2, 18: 2, 19: 2,                                                                                                                        # Mirai\n                    20: 3, 21: 3, 22: 3, 23: 3, 24: 3,                                                                                                          # Reconnaissance\n                    25: 4, 26: 4,                                                                                                                               # Spoofing\n                    27: 5, 28: 5, 29: 5, 30: 5, 31: 5, 32: 5,                                                                                                   # Web\n                    33: 6}                                                                                                                                      # Brute Force\n\n# Binary classes\ndict_2_classes = {  0: 0 ,                                                                                                                                      # Benign\n                    1 :1, 2:1,  3:1, 4:1, 5:1, 6:1, 7:1, 8:1, 9:1, 10:1, 11:1, 12:1, 13:1, 14:1, 15:1, 16:1,                                                    # DDoS and DoS  \n                    17: 1, 18: 1, 19: 1,                                                                                                                        # Mirai \n                    20: 1, 21: 1, 22: 1, 23: 1, 24: 1,                                                                                                          # Reconnaissance\n                    25: 1, 26: 1,                                                                                                                               # Spoofing\n                    27: 1, 28: 1, 29: 1, 30: 1, 31: 1, 32: 1,                                                                                                   # Web\n                    33: 1}                                                                                                                                      # Brute Force","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T05:19:54.124323Z","iopub.execute_input":"2025-09-22T05:19:54.124898Z","iopub.status.idle":"2025-09-22T05:19:54.139713Z","shell.execute_reply.started":"2025-09-22T05:19:54.124875Z","shell.execute_reply":"2025-09-22T05:19:54.139202Z"}},"outputs":[],"execution_count":90},{"id":"b341488c-b030-4d79-96ac-ef52166f4237","cell_type":"code","source":"df_sets = [k for k in os.listdir(DATASET_DIRECTORY) if k.endswith('.csv')]\ndf_sets.sort()\n\n# # Create the training and test sets\ntraining_sets = df_sets[:int(len(df_sets)*.8)]\ntest_sets = df_sets[int(len(df_sets)*.8):]\n\n# TODO - REMOVE THIS - Works on 20% of the data for low memory machines\n# Create the training and test sets - LOW MEMORY CLUDGE FOR JON\n# training_sets = df_sets[:int(len(df_sets)*.2)]\n# test_sets = df_sets[int(len(df_sets)*.8):]","metadata":{"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T05:19:54.140271Z","iopub.execute_input":"2025-09-22T05:19:54.140462Z","iopub.status.idle":"2025-09-22T05:19:54.161879Z","shell.execute_reply.started":"2025-09-22T05:19:54.140441Z","shell.execute_reply":"2025-09-22T05:19:54.161359Z"}},"outputs":[],"execution_count":91},{"id":"dde99b74","cell_type":"markdown","source":"---\n# TEMP CODE","metadata":{}},{"id":"4926641e","cell_type":"code","source":"# Set training_sets to the last entry of training_sets\ntraining_sets = training_sets[-1:]\nprint(f\"HACK TO REPLICATE ORIGINAL AUTHORS CODE WITH ONE FILE TRAIN - {training_sets}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T05:19:54.162819Z","iopub.execute_input":"2025-09-22T05:19:54.163022Z","iopub.status.idle":"2025-09-22T05:19:54.183936Z","shell.execute_reply.started":"2025-09-22T05:19:54.163008Z","shell.execute_reply":"2025-09-22T05:19:54.183272Z"}},"outputs":[{"name":"stdout","text":"HACK TO REPLICATE ORIGINAL AUTHORS CODE WITH ONE FILE TRAIN - ['0.05percent_8classes.csv']\n","output_type":"stream"}],"execution_count":92},{"id":"0c1fc92e","cell_type":"markdown","source":"Remove this if you have more than a morsel of memory\n\n---","metadata":{}},{"id":"6b4d10ad-299a-4741-bed8-dfb6d0a0e6fd","cell_type":"markdown","source":"# Create a new DataFrame that consists of all CSV datA\n\nThis is **memory intensive** as it will create a DataFrame with 36 million rows.","metadata":{}},{"id":"d95c0bce-0698-4e23-b070-3701040ac4f3","cell_type":"code","source":"\n# df = []\n\n# count = 0\n# for train_set in tqdm(training_sets):\n#     if count == 0:\n#         df = pd.read_csv(DATASET_DIRECTORY + train_set)\n#     else:\n#         df_new = pd.read_csv(DATASET_DIRECTORY + train_set)\n#         df = df.append(df_new, ignore_index=True)\n#     count = count + 1","metadata":{"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T05:19:54.253501Z","iopub.execute_input":"2025-09-22T05:19:54.253937Z","iopub.status.idle":"2025-09-22T05:19:54.257177Z","shell.execute_reply.started":"2025-09-22T05:19:54.253919Z","shell.execute_reply":"2025-09-22T05:19:54.256429Z"}},"outputs":[],"execution_count":93},{"id":"c75f3f94","cell_type":"code","source":"# # New faster method not using depreciated pandas append\n# dfs = []\n# for train_set in tqdm(training_sets):\n#     df_new = pd.read_csv(DATASET_DIRECTORY + train_set)\n#     dfs.append(df_new)\n# df = pd.concat(dfs, ignore_index=True)# FIX: Map string labels to categorical classes\n\n\n\n# FIX: Map string labels to categorical classes\nprint(\"Mapping string labels to categories...\")\nprint(f\"Unique string labels: {sorted(df['label'].unique())}\")\n\n# Check if these match any of our dictionaries\nprint(\"Checking label mapping...\")\n\n# Since you have 8 unique labels and want binary classification, \n# let's see what the actual labels are and map them appropriately\nunique_labels = sorted(df['label'].unique())\nprint(f\"The 8 unique labels are: {unique_labels}\")\n\n# Create a simple mapping - assuming 'Benign' = 0, everything else = 1 for binary\n# You can adjust this mapping based on what the actual labels are\nif 'Benign' in unique_labels or 'BenignTraffic' in unique_labels:\n    # Binary mapping: Benign = 0, all attacks = 1\n    df['label'] = df['label'].apply(lambda x: 0 if 'Benign' in str(x) else 1)\nelse:\n    # If no 'Benign' found, map alphabetically to 0-7\n    label_to_num = {label: i for i, label in enumerate(unique_labels)}\n    print(f\"Label mapping: {label_to_num}\")\n    df['label'] = df['label'].map(label_to_num)\n\nprint(f\"After mapping - Unique labels: {sorted(df['label'].unique())}\")\nprint(f\"Label distribution:\\n{df['label'].value_counts().sort_index()}\")\n\n# Preserve original labels  \ndf['original_label'] = df['label']\ndf['label_34'] = df['label']\n\nprint(\"Label processing completed successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T05:19:54.258716Z","iopub.execute_input":"2025-09-22T05:19:54.258982Z","iopub.status.idle":"2025-09-22T05:19:54.351149Z","shell.execute_reply.started":"2025-09-22T05:19:54.258951Z","shell.execute_reply":"2025-09-22T05:19:54.350519Z"}},"outputs":[{"name":"stdout","text":"Mapping string labels to categories...\nUnique string labels: [0, 1]\nChecking label mapping...\nThe 8 unique labels are: [0, 1]\nLabel mapping: {0: 0, 1: 1}\nAfter mapping - Unique labels: [0, 1]\nLabel distribution:\nlabel\n0      54908\n1    2279392\nName: count, dtype: int64\nLabel processing completed successfully!\n","output_type":"stream"}],"execution_count":94},{"id":"a5c6873b-ece2-4e99-a5a0-bb1733024e06","cell_type":"code","source":"df","metadata":{"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T05:19:54.351687Z","iopub.execute_input":"2025-09-22T05:19:54.351872Z","iopub.status.idle":"2025-09-22T05:19:54.836884Z","shell.execute_reply.started":"2025-09-22T05:19:54.351857Z","shell.execute_reply":"2025-09-22T05:19:54.836204Z"}},"outputs":[{"execution_count":95,"output_type":"execute_result","data":{"text/plain":"         flow_duration  header_length protocol_type  duration   rate  srate  \\\n0             0.000000              1          ICMP     63.89     26     26   \n1             0.022700          19157         CHAOS     63.85  16944  16944   \n2             0.059647          27289           UDP     64.00  16216  16216   \n3             0.010380           6312         CHAOS     71.64  12182  12182   \n4             0.024707          11925           UDP     64.00   8967   8967   \n...                ...            ...           ...       ...    ...    ...   \n2334295       0.000000             54           TCP     64.00      6      6   \n2334296       6.221767        4677541           TCP     56.50    682    682   \n2334297       0.000000             54           TCP     64.00      0      0   \n2334298       0.000000             54           TCP     64.00     20     20   \n2334299       0.104561          30374           UDP     64.00   6048   6048   \n\n         drate  fin_flag_number  syn_flag_number  rst_flag_number  ...  \\\n0          0.0            False            False            False  ...   \n1          0.0            False            False            False  ...   \n2          0.0            False            False            False  ...   \n3          0.0            False            False            False  ...   \n4          0.0            False            False            False  ...   \n...        ...              ...              ...              ...  ...   \n2334295    0.0            False            False            False  ...   \n2334296    0.0            False            False            False  ...   \n2334297    0.0             True            False             True  ...   \n2334298    0.0            False             True            False  ...   \n2334299    0.0            False            False            False  ...   \n\n                  iat  number       radius     covariance  variance  weight  \\\n0        8.312472e+07     9.5     4.566187      87.988464      0.12  141.55   \n1        8.303328e+07     9.5     0.476009       1.891419      0.06  141.55   \n2        8.312362e+07     9.5     0.000000       0.000000      0.00  141.55   \n3        8.310223e+07     9.5     0.846762       3.620116      0.10  141.55   \n4        8.310693e+07     9.5     0.000000       0.000000      0.00  141.55   \n...               ...     ...          ...            ...       ...     ...   \n2334295  8.331387e+07     9.5     0.000000       0.000000      0.00  141.55   \n2334296  2.316952e-04     5.5  1147.053800  777046.900000      0.90   38.50   \n2334297  8.334506e+07     9.5     0.000000       0.000000      0.00  141.55   \n2334298  8.298162e+07     9.5     0.000000       0.000000      0.00  141.55   \n2334299  8.310227e+07     9.5     0.000000       0.000000      0.00  141.55   \n\n         label  magnitude  original_label  label_34  \n0            1   9.260885               1         1  \n1            1  10.008313               1         1  \n2            1  10.000000               1         1  \n3            1  10.020020               1         1  \n4            1  10.000000               1         1  \n...        ...        ...             ...       ...  \n2334295      1  10.392304               1         1  \n2334296      1  67.472320               1         1  \n2334297      1  10.392304               1         1  \n2334298      1  10.392304               1         1  \n2334299      1  10.000000               1         1  \n\n[2334300 rows x 49 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>flow_duration</th>\n      <th>header_length</th>\n      <th>protocol_type</th>\n      <th>duration</th>\n      <th>rate</th>\n      <th>srate</th>\n      <th>drate</th>\n      <th>fin_flag_number</th>\n      <th>syn_flag_number</th>\n      <th>rst_flag_number</th>\n      <th>...</th>\n      <th>iat</th>\n      <th>number</th>\n      <th>radius</th>\n      <th>covariance</th>\n      <th>variance</th>\n      <th>weight</th>\n      <th>label</th>\n      <th>magnitude</th>\n      <th>original_label</th>\n      <th>label_34</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.000000</td>\n      <td>1</td>\n      <td>ICMP</td>\n      <td>63.89</td>\n      <td>26</td>\n      <td>26</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>8.312472e+07</td>\n      <td>9.5</td>\n      <td>4.566187</td>\n      <td>87.988464</td>\n      <td>0.12</td>\n      <td>141.55</td>\n      <td>1</td>\n      <td>9.260885</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.022700</td>\n      <td>19157</td>\n      <td>CHAOS</td>\n      <td>63.85</td>\n      <td>16944</td>\n      <td>16944</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>8.303328e+07</td>\n      <td>9.5</td>\n      <td>0.476009</td>\n      <td>1.891419</td>\n      <td>0.06</td>\n      <td>141.55</td>\n      <td>1</td>\n      <td>10.008313</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.059647</td>\n      <td>27289</td>\n      <td>UDP</td>\n      <td>64.00</td>\n      <td>16216</td>\n      <td>16216</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>8.312362e+07</td>\n      <td>9.5</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00</td>\n      <td>141.55</td>\n      <td>1</td>\n      <td>10.000000</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.010380</td>\n      <td>6312</td>\n      <td>CHAOS</td>\n      <td>71.64</td>\n      <td>12182</td>\n      <td>12182</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>8.310223e+07</td>\n      <td>9.5</td>\n      <td>0.846762</td>\n      <td>3.620116</td>\n      <td>0.10</td>\n      <td>141.55</td>\n      <td>1</td>\n      <td>10.020020</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.024707</td>\n      <td>11925</td>\n      <td>UDP</td>\n      <td>64.00</td>\n      <td>8967</td>\n      <td>8967</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>8.310693e+07</td>\n      <td>9.5</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00</td>\n      <td>141.55</td>\n      <td>1</td>\n      <td>10.000000</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2334295</th>\n      <td>0.000000</td>\n      <td>54</td>\n      <td>TCP</td>\n      <td>64.00</td>\n      <td>6</td>\n      <td>6</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>8.331387e+07</td>\n      <td>9.5</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00</td>\n      <td>141.55</td>\n      <td>1</td>\n      <td>10.392304</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2334296</th>\n      <td>6.221767</td>\n      <td>4677541</td>\n      <td>TCP</td>\n      <td>56.50</td>\n      <td>682</td>\n      <td>682</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>2.316952e-04</td>\n      <td>5.5</td>\n      <td>1147.053800</td>\n      <td>777046.900000</td>\n      <td>0.90</td>\n      <td>38.50</td>\n      <td>1</td>\n      <td>67.472320</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2334297</th>\n      <td>0.000000</td>\n      <td>54</td>\n      <td>TCP</td>\n      <td>64.00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>...</td>\n      <td>8.334506e+07</td>\n      <td>9.5</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00</td>\n      <td>141.55</td>\n      <td>1</td>\n      <td>10.392304</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2334298</th>\n      <td>0.000000</td>\n      <td>54</td>\n      <td>TCP</td>\n      <td>64.00</td>\n      <td>20</td>\n      <td>20</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>...</td>\n      <td>8.298162e+07</td>\n      <td>9.5</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00</td>\n      <td>141.55</td>\n      <td>1</td>\n      <td>10.392304</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2334299</th>\n      <td>0.104561</td>\n      <td>30374</td>\n      <td>UDP</td>\n      <td>64.00</td>\n      <td>6048</td>\n      <td>6048</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>8.310227e+07</td>\n      <td>9.5</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00</td>\n      <td>141.55</td>\n      <td>1</td>\n      <td>10.000000</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>2334300 rows × 49 columns</p>\n</div>"},"metadata":{}}],"execution_count":95},{"id":"489d18c8-7955-4021-9d09-6b5d517a0947","cell_type":"code","source":"df.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T05:19:54.837606Z","iopub.execute_input":"2025-09-22T05:19:54.837784Z","iopub.status.idle":"2025-09-22T05:19:54.846707Z","shell.execute_reply.started":"2025-09-22T05:19:54.837770Z","shell.execute_reply":"2025-09-22T05:19:54.845924Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 2334300 entries, 0 to 2334299\nData columns (total 49 columns):\n #   Column           Dtype  \n---  ------           -----  \n 0   flow_duration    float64\n 1   header_length    int64  \n 2   protocol_type    object \n 3   duration         float64\n 4   rate             int64  \n 5   srate            int64  \n 6   drate            float64\n 7   fin_flag_number  bool   \n 8   syn_flag_number  bool   \n 9   rst_flag_number  bool   \n 10  psh_flag_number  bool   \n 11  ack_flag_number  bool   \n 12  ece_flag_number  bool   \n 13  cwr_flag_number  bool   \n 14  ack_count        float64\n 15  syn_count        float64\n 16  fin_count        int64  \n 17  urg_count        int64  \n 18  rst_count        int64  \n 19  http             bool   \n 20  https            bool   \n 21  dns              bool   \n 22  telnet           bool   \n 23  smtp             bool   \n 24  ssh              bool   \n 25  irc              bool   \n 26  tcp              bool   \n 27  udp              bool   \n 28  dhcp             bool   \n 29  arp              bool   \n 30  icmp             bool   \n 31  ipv              bool   \n 32  llc              bool   \n 33  tot_sum          float64\n 34  min              float64\n 35  max              float64\n 36  avg              float64\n 37  std              float64\n 38  tot_size         float64\n 39  iat              float64\n 40  number           float64\n 41  radius           float64\n 42  covariance       float64\n 43  variance         float64\n 44  weight           float64\n 45  label            int64  \n 46  magnitude        float64\n 47  original_label   int64  \n 48  label_34         int64  \ndtypes: bool(21), float64(18), int64(9), object(1)\nmemory usage: 545.4+ MB\n","output_type":"stream"}],"execution_count":96},{"id":"0f1bcba0-8336-483a-95fb-ef600b42fd82","cell_type":"code","source":"df.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T05:19:54.848404Z","iopub.execute_input":"2025-09-22T05:19:54.848607Z","iopub.status.idle":"2025-09-22T05:19:56.864164Z","shell.execute_reply.started":"2025-09-22T05:19:54.848592Z","shell.execute_reply":"2025-09-22T05:19:56.863512Z"}},"outputs":[{"execution_count":97,"output_type":"execute_result","data":{"text/plain":"       flow_duration  header_length      duration          rate         srate  \\\ncount   2.334300e+06   2.334300e+06  2.334300e+06  2.334300e+06  2.334300e+06   \nmean    5.593242e+00   7.663165e+04  6.633568e+01  9.123290e+03  9.123290e+03   \nstd     2.627411e+02   4.609125e+05  1.393445e+01  9.963112e+04  9.963112e+04   \nmin     0.000000e+00   0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n25%     0.000000e+00   5.400000e+01  6.400000e+01  2.000000e+00  2.000000e+00   \n50%     0.000000e+00   5.400000e+01  6.400000e+01  1.500000e+01  1.500000e+01   \n75%     1.052728e-01   2.800000e+02  6.400000e+01  1.170000e+02  1.170000e+02   \nmax     7.463142e+04   9.865998e+06  2.550000e+02  8.388608e+06  8.388608e+06   \n\n              drate     ack_count     syn_count     fin_count     urg_count  \\\ncount  2.334300e+06  2.334300e+06  2.334300e+06  2.334300e+06  2.334300e+06   \nmean   2.545727e-06  9.055317e-02  3.303418e-01  7.407488e-02  6.168786e+00   \nstd    7.474065e-04  2.865076e-01  6.633365e-01  2.925268e-01  7.119865e+01   \nmin    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n25%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n50%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n75%    0.000000e+00  0.000000e+00  6.000000e-02  0.000000e+00  0.000000e+00   \nmax    6.060958e-01  5.600000e+00  1.263000e+01  8.000000e+01  4.164000e+03   \n\n       ...           iat        number        radius    covariance  \\\ncount  ...  2.334300e+06  2.334300e+06  2.334300e+06  2.334300e+06   \nmean   ...  8.317460e+07  9.498127e+00  4.711282e+01  3.086002e+04   \nstd    ...  1.704676e+07  8.190186e-01  2.270015e+02  3.340948e+05   \nmin    ...  0.000000e+00  1.000000e+00  0.000000e+00  0.000000e+00   \n25%    ...  8.307157e+07  9.500000e+00  0.000000e+00  0.000000e+00   \n50%    ...  8.312452e+07  9.500000e+00  0.000000e+00  0.000000e+00   \n75%    ...  8.334390e+07  9.500000e+00  5.059213e-01  1.344216e+00   \nmax    ...  1.676394e+08  1.500000e+01  1.546038e+04  1.435427e+08   \n\n           variance        weight         label     magnitude  original_label  \\\ncount  2.334300e+06  2.334300e+06  2.334300e+06  2.334300e+06    2.334300e+06   \nmean   9.641798e-02  1.415030e+02  9.764777e-01  1.312244e+01    9.764777e-01   \nstd    2.329740e-01  2.106680e+01  1.515552e-01  8.629887e+00    1.515552e-01   \nmin    0.000000e+00  1.000000e+00  0.000000e+00  9.165152e+00    0.000000e+00   \n25%    0.000000e+00  1.415500e+02  1.000000e+00  1.000000e+01    1.000000e+00   \n50%    0.000000e+00  1.415500e+02  1.000000e+00  1.039230e+01    1.000000e+00   \n75%    8.000000e-02  1.415500e+02  1.000000e+00  1.039672e+01    1.000000e+00   \nmax    1.000000e+00  2.446000e+02  1.000000e+00  1.434332e+02    1.000000e+00   \n\n           label_34  \ncount  2.334300e+06  \nmean   9.764777e-01  \nstd    1.515552e-01  \nmin    0.000000e+00  \n25%    1.000000e+00  \n50%    1.000000e+00  \n75%    1.000000e+00  \nmax    1.000000e+00  \n\n[8 rows x 27 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>flow_duration</th>\n      <th>header_length</th>\n      <th>duration</th>\n      <th>rate</th>\n      <th>srate</th>\n      <th>drate</th>\n      <th>ack_count</th>\n      <th>syn_count</th>\n      <th>fin_count</th>\n      <th>urg_count</th>\n      <th>...</th>\n      <th>iat</th>\n      <th>number</th>\n      <th>radius</th>\n      <th>covariance</th>\n      <th>variance</th>\n      <th>weight</th>\n      <th>label</th>\n      <th>magnitude</th>\n      <th>original_label</th>\n      <th>label_34</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>2.334300e+06</td>\n      <td>2.334300e+06</td>\n      <td>2.334300e+06</td>\n      <td>2.334300e+06</td>\n      <td>2.334300e+06</td>\n      <td>2.334300e+06</td>\n      <td>2.334300e+06</td>\n      <td>2.334300e+06</td>\n      <td>2.334300e+06</td>\n      <td>2.334300e+06</td>\n      <td>...</td>\n      <td>2.334300e+06</td>\n      <td>2.334300e+06</td>\n      <td>2.334300e+06</td>\n      <td>2.334300e+06</td>\n      <td>2.334300e+06</td>\n      <td>2.334300e+06</td>\n      <td>2.334300e+06</td>\n      <td>2.334300e+06</td>\n      <td>2.334300e+06</td>\n      <td>2.334300e+06</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>5.593242e+00</td>\n      <td>7.663165e+04</td>\n      <td>6.633568e+01</td>\n      <td>9.123290e+03</td>\n      <td>9.123290e+03</td>\n      <td>2.545727e-06</td>\n      <td>9.055317e-02</td>\n      <td>3.303418e-01</td>\n      <td>7.407488e-02</td>\n      <td>6.168786e+00</td>\n      <td>...</td>\n      <td>8.317460e+07</td>\n      <td>9.498127e+00</td>\n      <td>4.711282e+01</td>\n      <td>3.086002e+04</td>\n      <td>9.641798e-02</td>\n      <td>1.415030e+02</td>\n      <td>9.764777e-01</td>\n      <td>1.312244e+01</td>\n      <td>9.764777e-01</td>\n      <td>9.764777e-01</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>2.627411e+02</td>\n      <td>4.609125e+05</td>\n      <td>1.393445e+01</td>\n      <td>9.963112e+04</td>\n      <td>9.963112e+04</td>\n      <td>7.474065e-04</td>\n      <td>2.865076e-01</td>\n      <td>6.633365e-01</td>\n      <td>2.925268e-01</td>\n      <td>7.119865e+01</td>\n      <td>...</td>\n      <td>1.704676e+07</td>\n      <td>8.190186e-01</td>\n      <td>2.270015e+02</td>\n      <td>3.340948e+05</td>\n      <td>2.329740e-01</td>\n      <td>2.106680e+01</td>\n      <td>1.515552e-01</td>\n      <td>8.629887e+00</td>\n      <td>1.515552e-01</td>\n      <td>1.515552e-01</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>...</td>\n      <td>0.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>9.165152e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000e+00</td>\n      <td>5.400000e+01</td>\n      <td>6.400000e+01</td>\n      <td>2.000000e+00</td>\n      <td>2.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>...</td>\n      <td>8.307157e+07</td>\n      <td>9.500000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>1.415500e+02</td>\n      <td>1.000000e+00</td>\n      <td>1.000000e+01</td>\n      <td>1.000000e+00</td>\n      <td>1.000000e+00</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.000000e+00</td>\n      <td>5.400000e+01</td>\n      <td>6.400000e+01</td>\n      <td>1.500000e+01</td>\n      <td>1.500000e+01</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>...</td>\n      <td>8.312452e+07</td>\n      <td>9.500000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>1.415500e+02</td>\n      <td>1.000000e+00</td>\n      <td>1.039230e+01</td>\n      <td>1.000000e+00</td>\n      <td>1.000000e+00</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1.052728e-01</td>\n      <td>2.800000e+02</td>\n      <td>6.400000e+01</td>\n      <td>1.170000e+02</td>\n      <td>1.170000e+02</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>6.000000e-02</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>...</td>\n      <td>8.334390e+07</td>\n      <td>9.500000e+00</td>\n      <td>5.059213e-01</td>\n      <td>1.344216e+00</td>\n      <td>8.000000e-02</td>\n      <td>1.415500e+02</td>\n      <td>1.000000e+00</td>\n      <td>1.039672e+01</td>\n      <td>1.000000e+00</td>\n      <td>1.000000e+00</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>7.463142e+04</td>\n      <td>9.865998e+06</td>\n      <td>2.550000e+02</td>\n      <td>8.388608e+06</td>\n      <td>8.388608e+06</td>\n      <td>6.060958e-01</td>\n      <td>5.600000e+00</td>\n      <td>1.263000e+01</td>\n      <td>8.000000e+01</td>\n      <td>4.164000e+03</td>\n      <td>...</td>\n      <td>1.676394e+08</td>\n      <td>1.500000e+01</td>\n      <td>1.546038e+04</td>\n      <td>1.435427e+08</td>\n      <td>1.000000e+00</td>\n      <td>2.446000e+02</td>\n      <td>1.000000e+00</td>\n      <td>1.434332e+02</td>\n      <td>1.000000e+00</td>\n      <td>1.000000e+00</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 27 columns</p>\n</div>"},"metadata":{}}],"execution_count":97},{"id":"08029a2f","cell_type":"markdown","source":"## Map the y labels to integers","metadata":{}},{"id":"f6ed9fca","cell_type":"code","source":"# # Map y column to the dict_34_classes values\n# df['label'] = df['label'].map(dict_34_classes)\n# Preserve original labels before any mapping\ndf['original_label'] = df['label']\n\n# Map to 34-class numeric labels\ndf['label_34'] = df['original_label'].map(dict_34_classes)\n\n# By default, use label_34\ndf['label'] = df['label_34']\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T05:19:56.865025Z","iopub.execute_input":"2025-09-22T05:19:56.865283Z","iopub.status.idle":"2025-09-22T05:19:56.944454Z","shell.execute_reply.started":"2025-09-22T05:19:56.865266Z","shell.execute_reply":"2025-09-22T05:19:56.943930Z"}},"outputs":[],"execution_count":98},{"id":"0edb73a9-e0e6-44b2-8ad5-291e42fc3f0c","cell_type":"markdown","source":"# Save this output to a Pickle file","metadata":{}},{"id":"7dafe71b-84f3-4dea-b906-a4fe31f31ebd","cell_type":"code","source":"df.to_pickle('training_data.pkl')","metadata":{"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T05:19:56.945150Z","iopub.execute_input":"2025-09-22T05:19:56.945420Z","iopub.status.idle":"2025-09-22T05:19:57.818935Z","shell.execute_reply.started":"2025-09-22T05:19:56.945396Z","shell.execute_reply":"2025-09-22T05:19:57.818101Z"}},"outputs":[],"execution_count":99},{"id":"f819a842-d247-4b52-9e87-1d55b2d173e1","cell_type":"markdown","source":"We can now retrieve the dataset from the pkl in further work (pickle file approx 2GB compared to 12GB of CSV data).\n\n---","metadata":{}},{"id":"f41888ad","cell_type":"markdown","source":"# Read the pickle file\n","metadata":{}},{"id":"e109b533","cell_type":"code","source":"# Read the pickle file\ndf = pd.read_pickle('training_data.pkl')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T05:19:57.819788Z","iopub.execute_input":"2025-09-22T05:19:57.820076Z","iopub.status.idle":"2025-09-22T05:19:58.164909Z","shell.execute_reply.started":"2025-09-22T05:19:57.820054Z","shell.execute_reply":"2025-09-22T05:19:58.164337Z"}},"outputs":[],"execution_count":100},{"id":"ec2440de-ec3b-4bd4-b07a-15de88e2f82d","cell_type":"code","source":"# #################################Debugging################################\n# # DIAGNOSTIC: Check what the actual labels are in the dataset\n# print(\"Checking actual labels in the dataset...\")\n# print(f\"Original label column unique values: {df['original_label'].unique()}\")\n# print(f\"Number of unique original labels: {len(df['original_label'].unique())}\")\n# print(f\"Sample of original labels: {df['original_label'].head(10).tolist()}\")\n\n# # Check if original labels match dict_34_classes keys\n# dict_keys = list(dict_34_classes.keys())\n# print(f\"Dict_34_classes keys: {dict_keys[:10]}...\")  # Show first 10\n# print(f\"Do original labels match dict keys? {set(df['original_label'].unique()).issubset(set(dict_keys))}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T05:19:58.165533Z","iopub.execute_input":"2025-09-22T05:19:58.165729Z","iopub.status.idle":"2025-09-22T05:19:58.169233Z","shell.execute_reply.started":"2025-09-22T05:19:58.165713Z","shell.execute_reply":"2025-09-22T05:19:58.168536Z"}},"outputs":[],"execution_count":101},{"id":"6ed57157-2944-4f87-adc4-1e5446dc27e8","cell_type":"code","source":"# ################Debugging###################\n# # Check the raw label column from the CSV\n# print(\"Checking raw label column...\")\n# print(f\"Label column name: '{y_column}'\")\n# print(f\"Label column dtype: {df[y_column].dtype}\")\n# print(f\"Label column unique values: {df[y_column].unique()}\")\n# print(f\"Label column null count: {df[y_column].isnull().sum()}\")\n# print(f\"Total rows: {len(df)}\")\n\n# # Check if the label column exists and what it contains\n# if y_column in df.columns:\n#     print(f\"Label column exists. Sample values: {df[y_column].head(10).tolist()}\")\n# else:\n#     print(f\"ERROR: Label column '{y_column}' does not exist!\")\n#     print(f\"Available columns: {df.columns.tolist()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T05:19:58.170077Z","iopub.execute_input":"2025-09-22T05:19:58.170616Z","iopub.status.idle":"2025-09-22T05:19:58.186238Z","shell.execute_reply.started":"2025-09-22T05:19:58.170591Z","shell.execute_reply":"2025-09-22T05:19:58.185528Z"}},"outputs":[],"execution_count":102},{"id":"f294134b-9993-4a99-819e-6f2cc0d8ff0a","cell_type":"code","source":"# # RELOAD THE ORIGINAL DATA AND FIX LABELS\n# print(\"Reloading original data...\")\n# df = pd.read_csv(DATASET_DIRECTORY + training_sets[0])  # Reload the original CSV\n# print(f\"Original data shape: {df.shape}\")\n# print(f\"Original label column: {df.columns[-1]}\")  # Usually the last column\n# print(f\"Sample of actual labels in CSV: {df.iloc[:, -1].unique()[:10]}\")\n\n# # Check what the label column is actually called and what values it contains\n# label_col_name = df.columns[-1]  # Assume label is the last column\n# print(f\"Actual label values: {sorted(df[label_col_name].unique())}\")\n\n# # Now map these ACTUAL labels to your dict_34_classes\n# # If the labels are already numeric (0-33), just use them directly:\n# if df[label_col_name].dtype in ['int64', 'float64']:\n#     df['label'] = df[label_col_name]\n#     print(\"Labels were already numeric, using directly\")\n# else:\n#     # If they're strings, map them using dict_34_classes\n#     df['label'] = df[label_col_name].map(dict_34_classes)\n#     print(\"Labels mapped using dict_34_classes\")\n\n# print(f\"Final label distribution: {sorted(df['label'].unique())}\")\n# print(f\"Any NaN labels: {df['label'].isnull().sum()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T05:19:58.186980Z","iopub.execute_input":"2025-09-22T05:19:58.187632Z","iopub.status.idle":"2025-09-22T05:19:58.203112Z","shell.execute_reply.started":"2025-09-22T05:19:58.187614Z","shell.execute_reply":"2025-09-22T05:19:58.202452Z"}},"outputs":[],"execution_count":103},{"id":"32df3c6a-cdc7-4af5-856c-2ba64bcf4ebc","cell_type":"code","source":"# ######################Debugging##############\n# # CHECK FOR THE CORRECT LABEL COLUMN\n# print(\"Checking for correct label column...\")\n# print(f\"All columns in CSV: {df.columns.tolist()}\")\n# print(f\"Looking for column named: '{y_column}'\")\n\n# if y_column in df.columns:\n#     print(f\"Found '{y_column}' column!\")\n#     print(f\"Label column dtype: {df[y_column].dtype}\")\n#     print(f\"Unique labels in '{y_column}': {sorted(df[y_column].unique())}\")\n#     print(f\"Sample labels: {df[y_column].head(10).tolist()}\")\n    \n#     # Check if these are string labels that need mapping\n#     if df[y_column].dtype == 'object':\n#         print(\"Labels are strings - need mapping\")\n#         df['label'] = df[y_column].map(dict_34_classes)\n#     else:\n#         print(\"Labels are numeric - using directly\")\n#         df['label'] = df[y_column]\n# else:\n#     print(f\"ERROR: '{y_column}' column not found!\")\n#     print(\"Available columns:\", df.columns.tolist())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T05:19:58.203822Z","iopub.execute_input":"2025-09-22T05:19:58.204056Z","iopub.status.idle":"2025-09-22T05:19:58.225747Z","shell.execute_reply.started":"2025-09-22T05:19:58.204036Z","shell.execute_reply":"2025-09-22T05:19:58.225124Z"}},"outputs":[],"execution_count":104},{"id":"2e2e36d1-c7bf-431f-9433-3ec70f09736a","cell_type":"code","source":"# DEBUG: Check what happened to the data\nprint(f\"DataFrame shape after label mapping: {df.shape}\")\nprint(f\"Unique labels after mapping: {sorted(df['label'].unique())}\")\nprint(f\"Any NaN labels: {df['label'].isnull().sum()}\")\nprint(f\"Label value counts:\\n{df['label'].value_counts()}\")\n\n# If DataFrame is empty, something went wrong\nif len(df) == 0:\n    print(\"ERROR: DataFrame is empty! Reloading original data...\")\n    df = pd.read_csv(DATASET_DIRECTORY + training_sets[0])\n    print(f\"Reloaded shape: {df.shape}\")\n    print(f\"Original unique labels: {sorted(df['label'].unique())}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T05:19:58.226436Z","iopub.execute_input":"2025-09-22T05:19:58.226610Z","iopub.status.idle":"2025-09-22T05:19:58.269488Z","shell.execute_reply.started":"2025-09-22T05:19:58.226596Z","shell.execute_reply":"2025-09-22T05:19:58.268835Z"}},"outputs":[{"name":"stdout","text":"DataFrame shape after label mapping: (2334300, 49)\nUnique labels after mapping: [nan]\nAny NaN labels: 2334300\nLabel value counts:\nSeries([], Name: count, dtype: int64)\n","output_type":"stream"}],"execution_count":105},{"id":"fc0e2944-4d9a-45df-b058-6aeda1829961","cell_type":"code","source":"# EMERGENCY FIX: Reload and check the actual string labels\nprint(\"RELOADING to check actual labels...\")\ndf = pd.read_csv(DATASET_DIRECTORY + training_sets[0])\nprint(f\"Reloaded data shape: {df.shape}\")\n\n# Check the ACTUAL string labels in the dataset\nactual_labels = sorted(df['label'].unique())\nprint(f\"The actual 8 string labels are: {actual_labels}\")\n\n# Now create correct mapping based on what we actually have\n# Map based on the actual label names\nif 'Benign' in str(actual_labels):\n    # Binary: Benign=0, all others=1\n    df['label'] = df['label'].apply(lambda x: 0 if 'Benign' in str(x) else 1)\nelif 'BenignTraffic' in str(actual_labels):\n    df['label'] = df['label'].apply(lambda x: 0 if x == 'BenignTraffic' else 1)\nelse:\n    # Create a manual mapping for the 8 classes\n    label_mapping = {label: i for i, label in enumerate(actual_labels)}\n    print(f\"Creating mapping: {label_mapping}\")\n    df['label'] = df['label'].map(label_mapping)\n\nprint(f\"After CORRECT mapping: {sorted(df['label'].unique())}\")\nprint(f\"NaN count: {df['label'].isnull().sum()}\")\n\n# Preserve labels\ndf['original_label'] = df['label']\ndf['label_34'] = df['label']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T05:19:58.271437Z","iopub.execute_input":"2025-09-22T05:19:58.271830Z","iopub.status.idle":"2025-09-22T05:20:07.722921Z","shell.execute_reply.started":"2025-09-22T05:19:58.271788Z","shell.execute_reply":"2025-09-22T05:20:07.722266Z"}},"outputs":[{"name":"stdout","text":"RELOADING to check actual labels...\nReloaded data shape: (2334300, 47)\nThe actual 8 string labels are: ['Benign', 'BruteForce', 'DDoS', 'DoS', 'Mirai', 'Recon', 'Spoofing', 'Web']\nAfter CORRECT mapping: [0, 1]\nNaN count: 0\n","output_type":"stream"}],"execution_count":106},{"id":"ad30fdf1-6d0c-4a1a-8cea-0a6ae53288f0","cell_type":"markdown","source":"# Scale the input features","metadata":{"tags":[]}},{"id":"ae08745b-9b58-4fad-8754-7051afed7b8c","cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler, StandardScaler\n# scaler = StandardScaler()\n# df[X_columns] = scaler.fit_transform(df[X_columns])\n\nfrom sklearn.preprocessing import LabelEncoder\n\n# Check data types\nprint(\"Data types before preprocessing:\")\nprint(df[X_columns].dtypes)\n\n# Handle the protocol_type column (convert string to numeric)\nprint(f\"Unique protocol types: {df['protocol_type'].unique()}\")\nle = LabelEncoder()\ndf['protocol_type'] = le.fit_transform(df['protocol_type'])\nprint(f\"Protocol type encoded. New values: {sorted(df['protocol_type'].unique())}\")\n\n# Convert boolean columns to numeric (0/1)\nbool_columns = df.select_dtypes(include=['bool']).columns\nprint(f\"Converting boolean columns to numeric: {list(bool_columns)}\")\ndf[bool_columns] = df[bool_columns].astype(int)\n\n# Check if there are any non-numeric columns left in X_columns\nprint(\"\\nData types after preprocessing:\")\nnon_numeric_cols = []\nfor col in X_columns:\n    if df[col].dtype == 'object':\n        non_numeric_cols.append(col)\n        print(f\"Warning: {col} is still non-numeric: {df[col].dtype}\")\n\nif non_numeric_cols:\n    print(f\"Found non-numeric columns: {non_numeric_cols}\")\n    # Handle any remaining non-numeric columns\n    for col in non_numeric_cols:\n        if df[col].dtype == 'object':\n            le = LabelEncoder()\n            df[col] = le.fit_transform(df[col].astype(str))\n\n# Handle labels - check if they need mapping\nprint(f\"Unique labels before mapping: {sorted(df[y_column].unique())}\")\nif df[y_column].dtype == 'object':\n    df[y_column] = df[y_column].map(dict_34_classes)\n    print(\"Labels mapped using dict_34_classes\")\nelse:\n    print(\"Labels appear to already be numeric\")\n\n# Check for missing values\nmissing_values = df[X_columns].isnull().sum()\nif missing_values.sum() > 0:\n    print(f\"Missing values found:\\n{missing_values[missing_values > 0]}\")\n    df[X_columns] = df[X_columns].fillna(df[X_columns].mean())\n    print(\"Missing values filled with column means\")\n\n# Verify all columns are numeric before scaling\nprint(\"\\nFinal data types before scaling:\")\nfor col in X_columns:\n    dtype = df[col].dtype\n    print(f\"{col}: {dtype}\")\n    if not np.issubdtype(dtype, np.number):\n        print(f\"ERROR: {col} is not numeric!\")\n\n# Scale the features\n############################################Scaled######################################\nprint(\"Starting feature scaling...\")\nscaler = StandardScaler()\ndf[X_columns] = scaler.fit_transform(df[X_columns])\n\nprint(\"Data preprocessing completed successfully!\")\nprint(f\"Final dataset shape: {df.shape}\")\nprint(f\"Feature columns: {len(X_columns)}\")\nprint(f\"Unique labels after processing: {sorted(df[y_column].unique())}\")\n\n# Save the processed data\ndf.to_pickle('training_data.pkl')\nprint(\"Processed data saved to training_data.pkl\")\n\n# Also save the label encoder for later use\npickle.dump(le, open('protocol_type_encoder.pkl', 'wb'))\npickle.dump(scaler, open('feature_scaler.pkl', 'wb'))\nprint(\"Label encoder and scaler saved for later use\")","metadata":{"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T05:20:07.723597Z","iopub.execute_input":"2025-09-22T05:20:07.723837Z","iopub.status.idle":"2025-09-22T05:20:13.056246Z","shell.execute_reply.started":"2025-09-22T05:20:07.723810Z","shell.execute_reply":"2025-09-22T05:20:13.055358Z"}},"outputs":[{"name":"stdout","text":"Data types before preprocessing:\nflow_duration      float64\nheader_length        int64\nprotocol_type       object\nduration           float64\nrate                 int64\nsrate                int64\ndrate              float64\nfin_flag_number       bool\nsyn_flag_number       bool\nrst_flag_number       bool\npsh_flag_number       bool\nack_flag_number       bool\nece_flag_number       bool\ncwr_flag_number       bool\nack_count          float64\nsyn_count          float64\nfin_count            int64\nurg_count            int64\nrst_count            int64\nhttp                  bool\nhttps                 bool\ndns                   bool\ntelnet                bool\nsmtp                  bool\nssh                   bool\nirc                   bool\ntcp                   bool\nudp                   bool\ndhcp                  bool\narp                   bool\nicmp                  bool\nipv                   bool\nllc                   bool\ntot_sum            float64\nmin                float64\nmax                float64\navg                float64\nstd                float64\ntot_size           float64\niat                float64\nnumber             float64\nmagnitude          float64\nradius             float64\ncovariance         float64\nvariance           float64\nweight             float64\ndtype: object\nUnique protocol types: ['ICMP' 'CHAOS' 'UDP' 'TCP' 'PRM' 'RSVP' 'ST' 'HOPOPT' 'GRE' 'CBT' 'EGP'\n 'IGP' 'IPv6-Frag' 'IDRP' 'PUP' 'EMCON' 'NVP-II' 'IDPR-CMTP' 'IL' 'IPv6'\n 'IGMP' 'XNET' 'BBN-RCC-MON' 'GGP' 'ARGUS (deprecated)' 'SDRP' '3PC'\n 'TP++' 'IPv4' 'IPv6-Route' 'DCCP' 'DDP' 'MERIT-INP' 'MFE-NSP' 'XTP'\n 'IRTP' 'TRUNK-2' 'RDP' 'LEAF-1' 'LEAF-2' 'IDPR' 'HMP' 'NETBLT' 'TRUNK-1'\n 'MUX' 'ISO-TP4' 'XNS-IDP' 'DCN-MEAS']\nProtocol type encoded. New values: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\nConverting boolean columns to numeric: ['fin_flag_number', 'syn_flag_number', 'rst_flag_number', 'psh_flag_number', 'ack_flag_number', 'ece_flag_number', 'cwr_flag_number', 'http', 'https', 'dns', 'telnet', 'smtp', 'ssh', 'irc', 'tcp', 'udp', 'dhcp', 'arp', 'icmp', 'ipv', 'llc']\n\nData types after preprocessing:\nUnique labels before mapping: [0, 1]\nLabels appear to already be numeric\n\nFinal data types before scaling:\nflow_duration: float64\nheader_length: int64\nprotocol_type: int64\nduration: float64\nrate: int64\nsrate: int64\ndrate: float64\nfin_flag_number: int64\nsyn_flag_number: int64\nrst_flag_number: int64\npsh_flag_number: int64\nack_flag_number: int64\nece_flag_number: int64\ncwr_flag_number: int64\nack_count: float64\nsyn_count: float64\nfin_count: int64\nurg_count: int64\nrst_count: int64\nhttp: int64\nhttps: int64\ndns: int64\ntelnet: int64\nsmtp: int64\nssh: int64\nirc: int64\ntcp: int64\nudp: int64\ndhcp: int64\narp: int64\nicmp: int64\nipv: int64\nllc: int64\ntot_sum: float64\nmin: float64\nmax: float64\navg: float64\nstd: float64\ntot_size: float64\niat: float64\nnumber: float64\nmagnitude: float64\nradius: float64\ncovariance: float64\nvariance: float64\nweight: float64\nStarting feature scaling...\nData preprocessing completed successfully!\nFinal dataset shape: (2334300, 49)\nFeature columns: 46\nUnique labels after processing: [0, 1]\nProcessed data saved to training_data.pkl\nLabel encoder and scaler saved for later use\n","output_type":"stream"}],"execution_count":107},{"id":"2ecd8950-def4-40f7-8bf6-b4e31127a38c","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"37f437f6-5568-448e-bb63-eda7e3315750","cell_type":"code","source":"# Check what columns are actually in your dataset\nprint(\"Columns in your dataset:\")\nprint(df.columns.tolist())\nprint(f\"\\nDataset shape: {df.shape}\")\nprint(f\"\\nDataset info:\")\nprint(df.info())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T05:20:13.057155Z","iopub.execute_input":"2025-09-22T05:20:13.057435Z","iopub.status.idle":"2025-09-22T05:20:13.073295Z","shell.execute_reply.started":"2025-09-22T05:20:13.057411Z","shell.execute_reply":"2025-09-22T05:20:13.072475Z"}},"outputs":[{"name":"stdout","text":"Columns in your dataset:\n['flow_duration', 'header_length', 'protocol_type', 'duration', 'rate', 'srate', 'drate', 'fin_flag_number', 'syn_flag_number', 'rst_flag_number', 'psh_flag_number', 'ack_flag_number', 'ece_flag_number', 'cwr_flag_number', 'ack_count', 'syn_count', 'fin_count', 'urg_count', 'rst_count', 'http', 'https', 'dns', 'telnet', 'smtp', 'ssh', 'irc', 'tcp', 'udp', 'dhcp', 'arp', 'icmp', 'ipv', 'llc', 'tot_sum', 'min', 'max', 'avg', 'std', 'tot_size', 'iat', 'number', 'radius', 'covariance', 'variance', 'weight', 'label', 'magnitude', 'original_label', 'label_34']\n\nDataset shape: (2334300, 49)\n\nDataset info:\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 2334300 entries, 0 to 2334299\nData columns (total 49 columns):\n #   Column           Dtype  \n---  ------           -----  \n 0   flow_duration    float64\n 1   header_length    float64\n 2   protocol_type    float64\n 3   duration         float64\n 4   rate             float64\n 5   srate            float64\n 6   drate            float64\n 7   fin_flag_number  float64\n 8   syn_flag_number  float64\n 9   rst_flag_number  float64\n 10  psh_flag_number  float64\n 11  ack_flag_number  float64\n 12  ece_flag_number  float64\n 13  cwr_flag_number  float64\n 14  ack_count        float64\n 15  syn_count        float64\n 16  fin_count        float64\n 17  urg_count        float64\n 18  rst_count        float64\n 19  http             float64\n 20  https            float64\n 21  dns              float64\n 22  telnet           float64\n 23  smtp             float64\n 24  ssh              float64\n 25  irc              float64\n 26  tcp              float64\n 27  udp              float64\n 28  dhcp             float64\n 29  arp              float64\n 30  icmp             float64\n 31  ipv              float64\n 32  llc              float64\n 33  tot_sum          float64\n 34  min              float64\n 35  max              float64\n 36  avg              float64\n 37  std              float64\n 38  tot_size         float64\n 39  iat              float64\n 40  number           float64\n 41  radius           float64\n 42  covariance       float64\n 43  variance         float64\n 44  weight           float64\n 45  label            int64  \n 46  magnitude        float64\n 47  original_label   int64  \n 48  label_34         int64  \ndtypes: float64(46), int64(3)\nmemory usage: 872.7 MB\nNone\n","output_type":"stream"}],"execution_count":108},{"id":"841f18dd-f569-4c67-a320-54f5a2d1360a","cell_type":"markdown","source":"# Classification Problem (2-class, 8-class, or 34-class)\nSelect which size classification problem you want to solve.","metadata":{}},{"id":"99c225c6-a510-4652-bd04-2a6027743158","cell_type":"code","source":"binary_classifier = True\ngroup_classifier = False\nindividual_classifier = False\n\n# Labels are already correctly mapped as binary (0,1), so just set class_size\nif binary_classifier:\n    print(\"Binary 2 Class Classifier...\")\n    class_size = \"2\"\nelif group_classifier:\n    print(\"Group 8 Class Classifier...\")\n    class_size = \"8\" \nelse:\n    print(\"Individual 34 Class classifier...\")\n    class_size = \"34\"\n\nprint(f\"Labels are ready: {sorted(df['label'].unique())}\")\nprint(f\"Final dataset shape: {df.shape}\")","metadata":{"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T05:20:13.074072Z","iopub.execute_input":"2025-09-22T05:20:13.074331Z","iopub.status.idle":"2025-09-22T05:20:13.101851Z","shell.execute_reply.started":"2025-09-22T05:20:13.074314Z","shell.execute_reply":"2025-09-22T05:20:13.101159Z"}},"outputs":[{"name":"stdout","text":"Binary 2 Class Classifier...\nLabels are ready: [0, 1]\nFinal dataset shape: (2334300, 49)\n","output_type":"stream"}],"execution_count":109},{"id":"ffc76b81-34a2-4db2-84e9-664f4ea99ecd","cell_type":"markdown","source":"# Model Creation (LR, RF, MLP)","metadata":{"tags":[]}},{"id":"970ab1fc-d4d4-4394-88b0-85ce92992c71","cell_type":"code","source":"%%time\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neural_network import MLPClassifier\nimport pickle\nfrom datetime import datetime\n\nfrom sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n\nML_models = [\n    (\"LogisticRegression\", LogisticRegression(n_jobs=-1), f\"logreg-{class_size}class-model.pkl\"),\n    (\"RandomForestClassifier\", RandomForestClassifier(), f\"rf-{class_size}class-model.pkl\"),\n    (\"MLPClassifier\", MLPClassifier(), f\"mlp-{class_size}class-model.pkl\")\n]\n\ndef train_and_evaluate(name, model, model_file, df):\n    print(datetime.now(), f\" : Fit {name} model...\")\n    model.fit(df[X_columns], df[y_column])\n    print(datetime.now(), f\" : Fit {name} model complete...\")\n    \n    with open(model_file, \"wb\") as f:\n        pickle.dump(model, f)\n    \n    y_test = []\n    preds = []\n    for test_set in tqdm(test_sets):\n        d_test = pd.read_csv(DATASET_DIRECTORY + test_set)\n        \n        # DEBUG: Check what columns are in test data\n        print(f\"Test file columns: {d_test.columns.tolist()}\")\n        print(f\"Test file shape: {d_test.shape}\")\n        \n        # Find the label column (might be named differently)\n        if 'label' in d_test.columns:\n            label_col = 'label'\n        elif 'target' in d_test.columns:\n            label_col = 'target'\n        elif 'class' in d_test.columns:\n            label_col = 'class'\n        else:\n            # Assume last column is the label\n            label_col = d_test.columns[-1]\n            \n        print(f\"Using label column: '{label_col}'\")\n        print(f\"Sample labels: {d_test[label_col].unique()[:5]}\")\n        \n        # PREPROCESS TEST DATA SAME AS TRAINING DATA\n        # Handle protocol_type encoding\n        d_test['protocol_type'] = le.transform(d_test['protocol_type'])\n        \n        # Convert boolean columns to int\n        bool_columns = d_test.select_dtypes(include=['bool']).columns\n        d_test[bool_columns] = d_test[bool_columns].astype(int)\n        \n        # Handle any remaining non-numeric columns\n        for col in X_columns:\n            if d_test[col].dtype == 'object':\n                d_test[col] = le.transform(d_test[col].astype(str))\n        \n        # Apply scaler to preprocessed data\n        d_test[X_columns] = scaler.transform(d_test[X_columns])\n        \n        # Process labels - use the same string-to-binary mapping as training\n        if binary_classifier:\n            d_test[label_col] = d_test[label_col].apply(lambda x: 0 if 'Benign' in str(x) else 1)\n        \n        y_test += list(d_test[label_col].values)\n        y_pred = list(model.predict(d_test[X_columns]))\n        preds += y_pred\n        \n        break  # Only process first test file for debugging\n        \n    print(f\"##### {name} ({class_size} classes) #####\")\n    print('accuracy_score: ', accuracy_score(preds, y_test))\n    print('recall_score: ', recall_score(preds, y_test, average='macro'))\n    print('precision_score: ', precision_score(preds, y_test, average='macro'))\n    print('f1_score: ', f1_score(preds, y_test, average='macro'))\n    print('\\n')\nfor name, model, model_file in ML_models:\n    train_and_evaluate(name, model, model_file, df)","metadata":{"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T05:27:25.321211Z","iopub.execute_input":"2025-09-22T05:27:25.321445Z","iopub.status.idle":"2025-09-22T05:52:10.656602Z","shell.execute_reply.started":"2025-09-22T05:27:25.321430Z","shell.execute_reply":"2025-09-22T05:52:10.655850Z"}},"outputs":[{"name":"stdout","text":"2025-09-22 05:27:25.328138  : Fit LogisticRegression model...\n2025-09-22 05:27:49.789312  : Fit LogisticRegression model complete...\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/3 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Test file columns: ['flow_duration', 'header_length', 'protocol_type', 'duration', 'rate', 'srate', 'drate', 'fin_flag_number', 'syn_flag_number', 'rst_flag_number', 'psh_flag_number', 'ack_flag_number', 'ece_flag_number', 'cwr_flag_number', 'ack_count', 'syn_count', 'fin_count', 'urg_count', 'rst_count', 'http', 'https', 'dns', 'telnet', 'smtp', 'ssh', 'irc', 'tcp', 'udp', 'dhcp', 'arp', 'icmp', 'ipv', 'llc', 'tot_sum', 'min', 'max', 'avg', 'std', 'tot_size', 'iat', 'number', 'radius', 'covariance', 'variance', 'weight', 'magnitude', 'benign']\nTest file shape: (4668653, 47)\nUsing label column: 'benign'\nSample labels: [False  True]\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/3 [00:25<?, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"##### LogisticRegression (2 classes) #####\naccuracy_score:  0.9782159864954624\nrecall_score:  0.5\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"precision_score:  0.4891079932477312\nf1_score:  0.4944940255125707\n\n\n2025-09-22 05:28:27.636651  : Fit RandomForestClassifier model...\n2025-09-22 05:34:45.568131  : Fit RandomForestClassifier model complete...\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/3 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Test file columns: ['flow_duration', 'header_length', 'protocol_type', 'duration', 'rate', 'srate', 'drate', 'fin_flag_number', 'syn_flag_number', 'rst_flag_number', 'psh_flag_number', 'ack_flag_number', 'ece_flag_number', 'cwr_flag_number', 'ack_count', 'syn_count', 'fin_count', 'urg_count', 'rst_count', 'http', 'https', 'dns', 'telnet', 'smtp', 'ssh', 'irc', 'tcp', 'udp', 'dhcp', 'arp', 'icmp', 'ipv', 'llc', 'tot_sum', 'min', 'max', 'avg', 'std', 'tot_size', 'iat', 'number', 'radius', 'covariance', 'variance', 'weight', 'magnitude', 'benign']\nTest file shape: (4668653, 47)\nUsing label column: 'benign'\nSample labels: [False  True]\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/3 [01:01<?, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"##### RandomForestClassifier (2 classes) #####\naccuracy_score:  0.9759414546337027\nrecall_score:  0.5\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"precision_score:  0.48797072731685137\nf1_score:  0.49391213102243525\n\n\n2025-09-22 05:36:00.210703  : Fit MLPClassifier model...\n2025-09-22 05:50:16.178120  : Fit MLPClassifier model complete...\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/3 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Test file columns: ['flow_duration', 'header_length', 'protocol_type', 'duration', 'rate', 'srate', 'drate', 'fin_flag_number', 'syn_flag_number', 'rst_flag_number', 'psh_flag_number', 'ack_flag_number', 'ece_flag_number', 'cwr_flag_number', 'ack_count', 'syn_count', 'fin_count', 'urg_count', 'rst_count', 'http', 'https', 'dns', 'telnet', 'smtp', 'ssh', 'irc', 'tcp', 'udp', 'dhcp', 'arp', 'icmp', 'ipv', 'llc', 'tot_sum', 'min', 'max', 'avg', 'std', 'tot_size', 'iat', 'number', 'radius', 'covariance', 'variance', 'weight', 'magnitude', 'benign']\nTest file shape: (4668653, 47)\nUsing label column: 'benign'\nSample labels: [False  True]\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/3 [01:41<?, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"##### MLPClassifier (2 classes) #####\naccuracy_score:  0.9737294675787641\nrecall_score:  0.5\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"precision_score:  0.48686473378938205\nf1_score:  0.4933449510551558\n\n\nCPU times: user 39min 33s, sys: 25.1 s, total: 39min 58s\nWall time: 24min 45s\n","output_type":"stream"}],"execution_count":114},{"id":"d27b8867-5c34-453a-ba25-797959e46376","cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T05:27:02.259256Z","iopub.execute_input":"2025-09-22T05:27:02.259534Z","iopub.status.idle":"2025-09-22T05:27:02.268327Z","shell.execute_reply.started":"2025-09-22T05:27:02.259515Z","shell.execute_reply":"2025-09-22T05:27:02.267565Z"}},"outputs":[],"execution_count":113},{"id":"f241ec19-4db5-4fa0-8640-15f334a7d7f8","cell_type":"markdown","source":"# Calculate Test Performance metrics","metadata":{"tags":[]}},{"id":"1632303c-d95a-4461-b3e8-0eff5ae64a6d","cell_type":"code","source":"y_test = []\npreds = {i:[] for i in range(len(ML_models))}\nfor test_set in tqdm(test_sets):\n    d_test = pd.read_csv(DATASET_DIRECTORY + test_set)\n    \n    # PREPROCESS TEST DATA FIRST (same as training data)\n    # Handle protocol_type encoding\n    d_test['protocol_type'] = le.transform(d_test['protocol_type'])\n    \n    # Convert boolean columns to int\n    bool_columns = d_test.select_dtypes(include=['bool']).columns\n    d_test[bool_columns] = d_test[bool_columns].astype(int)\n    \n    # Handle any remaining non-numeric columns\n    for col in X_columns:\n        if d_test[col].dtype == 'object':\n            d_test[col] = le.transform(d_test[col].astype(str))\n    \n    # NOW apply scaler to preprocessed data\n    d_test[X_columns] = scaler.transform(d_test[X_columns])\n    \n    # Handle labels - different test files have different label formats\n    if 'benign' in d_test.columns:\n        # Boolean format: True/False\n        d_test[y_column] = d_test['benign'].astype(int)\n    elif y_column in d_test.columns:\n        # Check if labels are strings (need binary mapping) or already numeric\n        if d_test[y_column].dtype == 'object':\n            # String labels - map to binary (same as training data)\n            d_test[y_column] = d_test[y_column].apply(lambda x: 0 if 'Benign' in str(x) else 1)\n        else:\n            # Already numeric\n            d_test[y_column] = d_test[y_column].astype(int)\n    else:\n        # Use last column as label\n        last_col = d_test.columns[-1]\n        if d_test[last_col].dtype == 'object':\n            d_test[y_column] = d_test[last_col].apply(lambda x: 0 if 'Benign' in str(x) else 1)\n        else:\n            d_test[y_column] = d_test[last_col].astype(int)\n    \n    y_test += list(d_test[y_column].values)\n    \n    # Get predictions from all models\n    for i, (name, model, model_file) in enumerate(ML_models):\n        y_pred = list(model.predict(d_test[X_columns]))\n        preds[i] = preds[i] + y_pred","metadata":{"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T06:02:34.575994Z","iopub.execute_input":"2025-09-22T06:02:34.576533Z","iopub.status.idle":"2025-09-22T06:09:50.949809Z","shell.execute_reply.started":"2025-09-22T06:02:34.576511Z","shell.execute_reply":"2025-09-22T06:09:50.949126Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 3/3 [07:16<00:00, 145.38s/it]\n","output_type":"stream"}],"execution_count":119},{"id":"e5c38e9e-ad1e-4cdc-85cd-73d2aaa3852e","cell_type":"code","source":"from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n\n# Get model names for display\nML_names = [name for name, model, model_file in ML_models]\n\nprint(\"Model Evaluation Results:\")\nprint(\"=\" * 50)\n\nfor k, v in preds.items():\n    y_pred = v\n    model_name = ML_names[k]\n    \n    print(f\"##### {model_name} ({class_size} classes) #####\")\n    print(f'Accuracy Score: {accuracy_score(y_pred, y_test):.4f}')\n    print(f'Recall Score: {recall_score(y_pred, y_test, average=\"macro\"):.4f}')\n    print(f'Precision Score: {precision_score(y_pred, y_test, average=\"macro\"):.4f}')\n    print(f'F1 Score: {f1_score(y_pred, y_test, average=\"macro\"):.4f}')\n    print()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T06:12:21.376608Z","iopub.execute_input":"2025-09-22T06:12:21.377316Z","iopub.status.idle":"2025-09-22T06:14:11.152672Z","shell.execute_reply.started":"2025-09-22T06:12:21.377296Z","shell.execute_reply":"2025-09-22T06:14:11.152003Z"}},"outputs":[{"name":"stdout","text":"Model Evaluation Results:\n==================================================\n##### LogisticRegression (2 classes) #####\nAccuracy Score: 0.6629\nRecall Score: 0.6292\nPrecision Score: 0.5122\nF1 Score: 0.4327\n\n##### RandomForestClassifier (2 classes) #####\nAccuracy Score: 0.6658\nRecall Score: 0.6561\nPrecision Score: 0.5163\nF1 Score: 0.4403\n\n##### MLPClassifier (2 classes) #####\nAccuracy Score: 0.6647\nRecall Score: 0.6389\nPrecision Score: 0.5158\nF1 Score: 0.4410\n\n","output_type":"stream"}],"execution_count":120},{"id":"b963208b-d5b3-4b6f-b2cf-5114291e281b","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"5706c7a5-7a98-44f9-8044-fd3a2c538922","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"26030db2-c09c-46d2-9faf-164282dfe8f6","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}